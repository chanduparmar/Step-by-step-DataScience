{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 5>Understanding Data Science Pipeline</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science is OSEMN <a id=\"0\"></a>\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You’re awesome. I’m awesome. Data Science is OSEMN. Why is data science “awesome” you may ask?** Well, as the aspiring data scientist you are, you’re given the opportunity to hone your powers of both a wizard and a detective. By wizard, I mean having the powers to predict things automagically! And by detective, it’s having the ability to find unknown patterns and trends in your data!\n",
    "<img src=\"images/1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the typical work flow on how the data science pipeline works is a crucial step towards business understanding and problem solving. **If you are intimidated about how the data science pipeline works, say no more. This article is for you!** I found a very simple acronym from Hilary Mason and Chris Wiggins that you can use throughout your data science pipeline. That is O.S.E.M.N.\n",
    "\n",
    "------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **OSEMN Pipeline**<br>\n",
    "**O** — Obtaining our data<br>\n",
    "**S** — Scrubbing / Cleaning our data<br>\n",
    "**E** — Exploring / Visualizing our data will allow us to find patterns and trends<br>\n",
    "**M** — Modeling our data will give us our predictive power as a wizard<br>\n",
    "**N** — Interpreting our data\n",
    "\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Question\n",
    "So before we even begin the OSEMN pipeline, the most crucial and important step that we must take into consideration is understanding what problem we’re trying to solve. Let’s say this again. Before we even begin doing anything with “Data Science”, we must first take into consideration what problem we’re trying to solve. **If you have a small problem you want to solve, then at most you’ll get a small solution. If you have a BIG problem to solve, then you’ll have the possibility of a BIG solution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask yourself:\n",
    "<ul>\n",
    "<li>How can we translate data into dollars?</li>\n",
    "<li>What impact do I want to make with this data?</li>\n",
    "<li>What business value does our model bring to the table?</li>\n",
    "<li>What will save us lots of money?</li>\n",
    "<li>What can be done to make our business run more efficiently?</li>\n",
    "    \n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Your Data\n",
    "\n",
    "``` You cannot do anything as a data scientist without even having any data. As a rule of thumb, there are some things you must take into consideration when obtaining your data. You must identify all of your available datasets (which can be from the internet or external/internal databases). You must extract the data into a usable format (.csv, json, xml, etc..)```\n",
    "\n",
    "<img src=\"images/2.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skills Required:\n",
    "\n",
    "1. **Database Management:** MySQL, PostgresSQL,MongoDB\n",
    "2. **Querying Relational Databases**\n",
    "3. **Retrieving Unstructured Data:** text, videos, audio files, documents\n",
    "4. **Distributed Storage:** Hadoops, Apache Spark/Flink\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrubbing / Cleaning Your Data\n",
    "<img src=\"images/3.png\">\n",
    "\n",
    "**Clean up on column 5!**|This phase of the pipeline should require the most time and effort. Because the results and output of your machine learning model is only as good as what you put into it. Basically, garbage in garbage out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective:\n",
    "\n",
    "**Examine the data:** understand every feature you’re working with, identify errors, missing values, and corrupt records\n",
    "**Clean the data:** throw away, replace, and/or fill missing values/errors\n",
    "## Skills Required:\n",
    "\n",
    "**Scripting language:** Python, R, SAS <br>\n",
    "**Data Wrangling Tools:** Python Pandas, R <br>\n",
    "**Distributed Processing:** Hadoop, Map Reduce / Spark<br>\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now during the exploration phase, we try to understand what patterns and values our data has. We’ll be using different types of visualizations and statistical testings to back up our findings. This is where we will be able to derive hidden meanings behind our data through various graphs and analysis. Go out and explore!\n",
    " <img src=\"images/4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "\n",
    "1. Find patterns in your data through visualizations and charts\n",
    "2. Extract features by using statistics to identify and test significant variables\n",
    "\n",
    "## Skills Required:\n",
    "\n",
    "**Python:** Numpy, Matplotlib, Pandas, Scipy <br>\n",
    "**R:** GGplot2, Dplyr<br>\n",
    "**Inferential statistics**<br>\n",
    "**Experimental Design** <br>\n",
    "**Data Visualization** <br>\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling (Machine Learning)\n",
    "<img src=\"images/4.jpeg\" width=500px>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the fun part. Models are general rules in a statistical sense.Think of a machine learning model as tools in your toolbox. You will have access to many algorithms and use them to accomplish different business goals. The better features you use the better your predictive power will be. After cleaning your data and finding what features are most important, using your model as a predictive tool will only enhance your business decision making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "\n",
    "**In-depth Analytics:** create predictive models/algorithms<br>\n",
    "**Evaluate and refine the model**<hr>\n",
    "## Skills Required:\n",
    "\n",
    "**Machine Learning:** Supervised/Unsupervised algorithms <br>\n",
    "**Evaluation methods** <br>\n",
    "**Machine Learning Libraries:** Python (Sci-kit Learn) / R (CARET) <br>\n",
    "**Linear algebra & Multivariate Calculus** <br>\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting (Data Storytelling)\n",
    "<img src=\"images/5.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It’s story time!** The most important step in the pipeline is to understand and learn how to explain your findings through communication. Telling the story is key, don’t underestimate it. It’s about connecting with people, persuading them, and helping them. The art of understanding your audience and connecting with them is one of the best part of data storytelling <hr>\n",
    "\n",
    "** Emotion plays a big role in data storytelling.** People aren’t going to magically understand your findings. The best way to make an impact is telling your story through emotion. We as humans are naturally influenced by emotions. If you can tap into your audiences’ emotions, then you my friend, are in control. When you’re presenting your data, keep in mind the power of psychology. The art of understanding your audience and connecting with them is one of the best part of data storytelling.\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Model\n",
    "<img src=\"images/6.jpg\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last phase of Data Science pipeline is to deploy machine learning model in the production.\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "https://towardsdatascience.com/a-beginners-guide-to-the-data-science-pipeline-a4904b2d8ad3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
